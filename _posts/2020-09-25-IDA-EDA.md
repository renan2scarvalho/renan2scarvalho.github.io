---
layout: post
title: IDA and EDA, what is this?
subtitle: Understanding the conceptual frameworks of IDA and EDA
thumbnail-img: https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcQrTyMxUic222An0o3kZeGvy6PGFNACLEsxig&usqp=CAU
#share-img: 
gh-repo: renan2scarvalho/
gh-badge: [star, fork, follow]
tags: [data science, data analysis, statistics]
comments: true
---

Nowadays, data is ubiquitous, hence, is necessary analyze it with scrutiny. In this context, a data analysist (conceptual context, not enterprise *fix-it* employee) work would be analyze the data, and just that, and this is what we'll talk about here. And by analyzing data I mean find what that that is about, find missing values, find trends, and finally, after all these steps, support decision makers, or in other words, business. So let's now approach our subjects.

While **IDA** stands for **Initial Data Analysis**, **EDA** stands for **Exploratory Data Analysis**. 
Their names look similar, but what's the main difference between them? What are they used for? Our target on this post is to address this difference, 
understanding clearly the *conceptual framework* for both analysis.
So let's *check it out!*

## 1. IDA

*Initial Data Analysis (IDA)* are all steps that are took *after data collection* and *prior to any formal statistic analysis*, which aims to answer the research question. So ideally, IDA should be carried alongside data collections, aiming to detect and handle issues as soon as possible [[1]](https://cstat.msu.edu/feature/initial-data-analysis). A large amount of time is usually allocated to statistical analysis, such as 80%, time spent with data cleaning and preparation. But carrying out these steps in an informal or unstructured way - i.e. neglecting or disorganized, may result in large and non-transparent impact on conclusions. So this is the main point of IDA, while targeting the research question, document changes to keep transparency [[2]](https://reader.elsevier.com/reader/sd/pii/S0022522315017948?token=07FBCC432E99AD4028F1B28789FBBECDEF2E6EE063BEFBC9A765FF4E7974C6127C697422D6663B03E56BD272033E696C). Examples are information gathered after IDA data cleaning, exclusion of cases, unusual observation, creating of new or transformed variables, distributions, or missing data patterns [[3]](https://obsstudies.org/wp-content/uploads/2018/04/idarev2.pdf). \
In a conceptual framework, IDA can be thought as a process of data inspection divided into some steps, where some authors divide into three, while others divide into six steps. Here we will show the *six steps* path as shown in [[3]](https://obsstudies.org/wp-content/uploads/2018/04/idarev2.pdf), as in the Figure above:

![image](https://user-images.githubusercontent.com/63553829/94266078-fa784600-ff0f-11ea-896f-222cfc91b213.png){: .align-center}

### 1.1. Metadata setup

Sometimes the dataset alone isn't sufficient to do a meaningful analysis, so background information is needed, or, in other words, *metadata* - "structured information that describes, explains, locates, or otherwise makes it easier to retrieve, use, or manage an information". Here we have **technical metadata**, such as variables and values, data type, measurement unit, plausability lmits or codes for missing values, essentail for IDA data cleaning and data screening; and **conceptual data**, which relates to the background of data collection and its implementation, regarding design (data sources and collection methods), recruitment (target population, sampling methods, time of data collection), or study (validation status of instruments, training of examiners). \
Metadata of relevance msut be added in a systematic way so that one can cover all elements of interest. A good practice is to set up all relevant metadata into an electronic form such as databases (e.g. MySQL) before starting the study.

### 1.2. Data cleaning

As the name says, here data is processed in order to arrive at a cleaned dataset in the needed format for the statistical analysis. This may include several different steps such as creating of new variables, splitting or merging datasets, and must be performed in a systematic way to find data errors and, if possible, correct them.








Some people classify IDA as only assessing for missing values, which now can be clearly viewed as an oversimplification, once the process, as shown, is broader.


## EDA














